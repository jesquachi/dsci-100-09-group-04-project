{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4296edc4-4a4c-471a-9c26-497773d3231a",
   "metadata": {},
   "source": [
    "# DSCI 100 09 Group 04 Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6e3ac2-ed6f-4a89-a83b-cbd2f9693971",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Introduction\n",
    "\n",
    "\"The HTRU2 dataset consists of pulsar candidates from the High Time Resolution Universe Survey (South).\" Pulsars are a type of Neutron star that rotate rapidly and emit radio signals. Their unique radio emission patterns hold scientific significance and require labeling individualistic pulsar candidates into two classes: 0 (Negative/Spurious) and 1 (Positive/Real Pulsar).\n",
    "\n",
    "With this dataset, we want to determine the relationship between the transmitted radio waves of pulsar stars, visualize the strong relationships between variables, and eventually create a KNN classification model to help classify new incoming observations based off of the current dataset as a training set. More specifically, we want to visualize and observe how the **skewness** and **kurtosis** can determine the class of a pulsar star."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fdda6c-0a1f-4911-bbdb-c9637f943f4f",
   "metadata": {},
   "source": [
    "### Methods\n",
    "\n",
    "In our data analysis, we want to visualize and investigate the relationship between the integrated profiles for *skewness* and *kurtosis* of pulsar stars. Through this investigation, we will create a classification model that will classify the pulsar stars based on given observations.\n",
    "\n",
    "The general process to work towards our goal is to start with loading and wrangling the data for quick and easy discernment and comprehension of the observations we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933effb5-23f8-4c41-85aa-5d98a0785aea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(tidyverse) \n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "set.seed(1000904)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7eaa2f-d7c8-4d72-a15c-ae01912fddef",
   "metadata": {},
   "source": [
    "#### Step 1: Loading Data\n",
    "\n",
    "Load the data set from the web. In this case, we downloaded the data set from the web and added it to a github repository and loaded the *.csv* file from there. Prior to this report, in our proposal, we had wrangled our data to look more tidy. We also used the *glimpse()* function to view how many rows exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6028af-08f0-4468-892e-83af73561388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pulsar_data <- read_csv(\"https://raw.githubusercontent.com/jesquachi/dsci-100-09-group-04-project/main/HTRU_2.csv\", \n",
    "                         col_names = FALSE) |>   #reading data into rand giving the column readable names\n",
    "                            rename(Mean_IP = X1,\n",
    "                                   SD_IP = X2,\n",
    "                                   Kurtosis_IP = X3,\n",
    "                                   Skewness_IP = X4,\n",
    "                                   Mean_DM_SNR = X5,\n",
    "                                   SD_DM_SNR = X6,\n",
    "                                   Kurtosis_DM_SNR = X7,\n",
    "                                   Skewness_DM_SNR = X8,\n",
    "                                   Class = X9) |>\n",
    "                            mutate(Class = as_factor(Class)) |>\n",
    "                            mutate(Class = fct_recode(Class, \"Spurious\" = \"0\", \"Real Pulsar\" = \"1\"))\n",
    "glimpse(pulsar_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46169e6f-5b3f-44e1-955c-8c8ac0d1e68e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 2: Summarizing Data and Creating Training set Summaries\n",
    "\n",
    "First, we made a table looking at the distinct classes and the percentage of observations in each class. Then we dropped any values and we started to split our data set into training and testing. With the newly split training set, we make another table looking at the classes of our training set and the percentage of observations in each class within our new training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d24140-7a68-4df5-be2f-4969986bb159",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obs <- nrow(pulsar_data)\n",
    "pulsar_data |>\n",
    "  group_by(Class) |>\n",
    "  summarize(\n",
    "    count = n(),\n",
    "    percentage = n() / obs * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d317ff-e722-4b07-8ca4-6c167b4a1a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
